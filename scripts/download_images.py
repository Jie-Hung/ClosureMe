import os
import requests
import boto3
from dotenv import load_dotenv
import json
from urllib.parse import urlparse

load_dotenv()

API_URL = os.getenv("API_URL")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_S3_BUCKET = os.getenv("AWS_S3_BUCKET")

with open("config.json", "r") as f:
    image_dir = json.load(f)["image_download_dir"]

os.makedirs(image_dir, exist_ok=True)

s3 = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
)

try:
    res = requests.get(f"{API_URL}/get-pending-images")
    res.raise_for_status()
    images = res.json()
except Exception as e:
    print("âŒ ç„¡æ³•å–å¾—åœ–ç‰‡æ¸…å–®:", e)
    exit(1)

if not images:
    print("âœ… æ²’æœ‰å¾…è™•ç†åœ–ç‰‡ã€‚")
    exit(0)

downloaded_count = 0
skipped_count = 0

for img in images:
    url = img["file_path"]
    file_name = os.path.basename(urlparse(url).path)
    local_path = os.path.join(image_dir, file_name)
    upload_batch = img["upload_batch"]

    if os.path.exists(local_path):
        print(f"âš ï¸  å·²å­˜åœ¨æœ¬åœ°ï¼Œç•¥éä¸‹è¼‰ï¼š{file_name}")
        skipped_count += 1
        continue

    try:
        s3_key = urlparse(url).path.lstrip("/")
        s3.download_file(AWS_S3_BUCKET, s3_key, local_path)
        print(f"âœ… å·²ä¸‹è¼‰ï¼š{file_name} (æ‰¹æ¬¡ï¼š{upload_batch})")
        downloaded_count += 1
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—ï¼š{file_name}ï¼ŒéŒ¯èª¤ï¼š{e}")

print("\nğŸ“Š ä¸‹è¼‰çµ±è¨ˆ")
print(f"   âœ… æˆåŠŸä¸‹è¼‰ï¼š{downloaded_count} å€‹")
print(f"   âš ï¸ å·²å­˜åœ¨è·³éï¼š{skipped_count} å€‹")
print(f"   ğŸ“‚ æœ¬åœ°è³‡æ–™å¤¾ï¼š{image_dir}")